# -*- coding: utf-8 -*-
import os
import uuid
import streamlit as st
import pandas as pd
from dotenv import load_dotenv
from datasets import load_dataset

# Haystack bileÅŸenleri
from haystack import Pipeline
from haystack.dataclasses import Document
from haystack.components.embedders import (
    SentenceTransformersDocumentEmbedder,
    SentenceTransformersTextEmbedder,
)
from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.builders import ChatPromptBuilder
from haystack.components.writers import DocumentWriter
from haystack_integrations.components.generators.google_genai import GoogleGenAIChatGenerator

# ------------------------------------------------------------
# Ortam deÄŸiÅŸkenleri
# ------------------------------------------------------------
load_dotenv()
HF_TOKEN = os.getenv("HF_TOKEN")
# Modeli .env'den oku; yoksa gÃ¼venli varsayÄ±lan kullan
MODEL_NAME = os.getenv("GENAI_MODEL", "gemini-2.5-flash")

# ------------------------------------------------------------
# YardÄ±mcÄ±: SWEâ€‘ReBench satÄ±rÄ±ndan iÃ§erik oluÅŸtur
# ------------------------------------------------------------
PRIMARY_FIELDS = ["problem_statement", "hints_text"]        # Soru/aÃ§Ä±klama
ANSWER_FIELDS  = ["patch", "test_patch"]                    # Ã‡Ã¶zÃ¼m/kod/diff

def build_content_from_row(row: dict) -> str:
    parts = []
    for k in PRIMARY_FIELDS:
        v = row.get(k)
        if isinstance(v, str) and v.strip():
            parts.append(f"{k.replace('_',' ').title()}:\n{v.strip()}")
    for k in ANSWER_FIELDS:
        v = row.get(k)
        if isinstance(v, str) and v.strip():
            parts.append(f"{k.replace('_',' ').title()}:\n{v.strip()}")
    return "\n\n".join(parts).strip()

# ------------------------------------------------------------
# Veri YÃ¼kleme ve HazÄ±rlama
# ------------------------------------------------------------
@st.cache_resource
def load_and_prepare_data():
    st.info("ğŸ’¡ SWE-ReBench veri seti yÃ¼kleniyor...")
    try:
        ds = load_dataset("nebius/SWE-rebench", split="test", token=HF_TOKEN)
        df = pd.DataFrame(ds)

        if df.empty:
            st.warning("âš ï¸ Veri seti boÅŸ geldi.")
            return []

        documents = []
        for _, row in df.iterrows():
            rowd = row.to_dict()
            content = build_content_from_row(rowd)
            if not content:
                continue

            meta = {
                "instance_id": str(rowd.get("instance_id", "")),
                "repo":        str(rowd.get("repo", "")),
                "created_at":  str(rowd.get("created_at", "")),
                "license":     str(rowd.get("license_name", "")),
            }
            documents.append(
                Document(content=content, meta=meta, id=str(uuid.uuid4()))
            )

        st.success(f"âœ… {len(documents)} belge yÃ¼klendi.")
        return documents

    except Exception as e:
        st.error(f"Veri yÃ¼klenirken hata oluÅŸtu: {e}")
        return []

# ------------------------------------------------------------
# VektÃ¶r VeritabanÄ± (Embedding + Indexleme)
# ------------------------------------------------------------
@st.cache_resource
def create_vector_db(documents):
    if not documents:
        st.warning("âš ï¸ Belgeler bulunamadÄ±.")
        return None

    st.info("ğŸ§  Embedding iÅŸlemi yapÄ±lÄ±yor...")
    try:
        document_store = InMemoryDocumentStore()
        # TR/EN iÃ§in Ã§ok dilli model
        embedder = SentenceTransformersDocumentEmbedder(
            model="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )

        indexing = Pipeline()
        indexing.add_component("embedder", embedder)
        indexing.add_component("writer", DocumentWriter(document_store=document_store))
        indexing.connect("embedder.documents", "writer.documents")

        indexing.run({"embedder": {"documents": documents}})

        st.success("âœ… VektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu!")
        return document_store

    except Exception as e:
        st.error(f"VektÃ¶r veritabanÄ± oluÅŸturulurken hata oluÅŸtu: {e}")
        return None

# ------------------------------------------------------------
# RAG Pipeline Kurulumu
# ------------------------------------------------------------
@st.cache_resource
def build_rag_pipeline(_document_store):
    try:
        text_embedder = SentenceTransformersTextEmbedder(
            model="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        retriever = InMemoryEmbeddingRetriever(
            document_store=_document_store, top_k=8
        )

        template = """
        {% message role="system" %}
        AÅŸaÄŸÄ±daki "BaÄŸlam" iÃ§indeki parÃ§alarÄ± Ã–NCELÄ°KLE kullanarak kÄ±sa, net ve doÄŸru bir yanÄ±t ver.
        BaÄŸlam azsa da soruyu yanÄ±tlamaya Ã§alÄ±ÅŸ; varsayÄ±m yaparsan belirt.
        YanÄ±t dili: TÃ¼rkÃ§e.
        Sonunda "Kaynaklar:" baÅŸlÄ±ÄŸÄ±yla kullandÄ±ÄŸÄ±n parÃ§alardan kÄ±saca liste ver (varsa).
        {% endmessage %}

        {% message role="user" %}
        Soru: {{ question }}

        BaÄŸlam ({{ documents|length }} parÃ§a):
        {% for d in documents %}
        - {{ d.content }}
        {% endfor %}
        {% endmessage %}
        """

        chat_prompt = ChatPromptBuilder(
            template=template,
            required_variables=["question", "documents"]
        )

        # Ã–NEMLÄ°: model adÄ±nÄ± .env'den aldÄ±k; baÅŸÄ±nda "models/" yok
        generator = GoogleGenAIChatGenerator(
            model=MODEL_NAME
        )

        pipe = Pipeline()
        pipe.add_component("text_embedder", text_embedder)
        pipe.add_component("retriever", retriever)
        pipe.add_component("chat_prompt", chat_prompt)
        pipe.add_component("generator", generator)

        # AkÄ±ÅŸ: embedder â†’ retriever â†’ chat_prompt â†’ generator
        pipe.connect("text_embedder.embedding", "retriever.query_embedding")
        pipe.connect("retriever.documents", "chat_prompt.documents")
        pipe.connect("chat_prompt.prompt", "generator.messages")

        st.success("âœ… RAG pipeline baÅŸarÄ±yla oluÅŸturuldu!")
        return pipe

    except Exception as e:
        st.error(f"RAG pipeline oluÅŸturulamadÄ±: {e}")
        return None

# ------------------------------------------------------------
# Streamlit ArayÃ¼zÃ¼
# ------------------------------------------------------------
def main():
    st.set_page_config(page_title="ğŸ’¡ SWE-RAG Kod AsistanÄ±", page_icon="ğŸ¤–")
    st.title("ğŸ’¡ SWE-RAG Kod AsistanÄ±")
    st.caption("SWE-ReBench veri seti Ã¼zerinde kod tabanlÄ± RAG soru-cevap sistemi.")
    # UI'da hangi modelin kullanÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶ster
    has_key = bool(os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY"))
    st.caption(f"Model: {MODEL_NAME}  |  API key set: {'YES' if has_key else 'NO'}")

    documents = load_and_prepare_data()
    document_store = create_vector_db(documents)
    rag_pipeline = build_rag_pipeline(document_store)

    if not rag_pipeline:
        st.stop()

    st.divider()
    st.subheader("ğŸ§© Kodla ilgili sorular sorabilirsiniz:")

    show_sources = st.checkbox("ğŸ” Ä°lk 3 kaynaÄŸÄ± gÃ¶ster (debug)")

    if prompt := st.chat_input("Ã–rn: Python'da two pointers tekniÄŸi nedir?"):
        st.chat_message("user").markdown(prompt)

        with st.spinner("Model yanÄ±t oluÅŸturuyor..."):
            try:
                result = rag_pipeline.run({
                    "text_embedder": {"text": prompt},
                    "chat_prompt": {"question": prompt}
                })

                # YanÄ±t
                replies = result.get("generator", {}).get("replies", [])
                if replies:
                    msg = replies[0]
                    answer = getattr(msg, "text", str(msg))
                else:
                    answer = "YanÄ±t alÄ±namadÄ±."

                # KaynaklarÄ± gÃ¶ster (opsiyonel)
                if show_sources:
                    docs = result.get("retriever", {}).get("documents", [])
                    with st.expander("ğŸ” KullanÄ±lan/Ã§Ä±karÄ±lan ilk 3 parÃ§a"):
                        if not docs:
                            st.write("_Retriever belge dÃ¶ndÃ¼rmedi._")
                        else:
                            for i, d in enumerate(docs[:3], start=1):
                                st.markdown(f"**Kaynak {i}:**  \nmeta: {d.meta}")
                                st.code((d.content or "")[:1500])

            except Exception as e:
                answer = f"Hata: {e}"

        st.chat_message("assistant").markdown(answer)

# ------------------------------------------------------------
if __name__ == "__main__":
    main()
